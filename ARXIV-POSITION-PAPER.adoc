= Journey Grammar for Databases: A Position Paper on Exploratory Data Cartography
Jonathan D.A. Jewell <jonathan.jewell@open.ac.uk>
:doctype: article
:toc: left
:toclevels: 3
:license: PMPL-1.0-or-later
:keywords: database metadata, data catalogs, epistemology, cartography, semantic web, unknown unknowns
:categories: cs.DB, cs.AI, cs.LO, cs.DL

== Abstract

For two decades, we have obsessed over the **black box problem**: interpreting opaque machine learning models, understanding complex systems, explaining algorithmic decisions. We have been looking in the wrong direction. Our databases are transparent—we built them, we know their schemas, we can inspect their contents. **The boxes are white, not black.** The real mystery lies in the **darkness beyond our measurements**: the vast unmeasured territory of reality that our databases only partially map. We propose a paradigm shift from interpretability (opening black boxes) to **exploratory data cartography** (mapping dark territory). **Journey Grammar for Databases (JGD)** provides the formal infrastructure for this inversion: a compositional grammar for describing phenomenal databases (D_p—our observations) in relation to noumenal reality (D_n—the territory itself), tracking spatiotemporal coverage, identifying known blind spots (Zone 2), acknowledging unknown unknowns (Zone 3), and coordinating federated exploration. JGD succeeds VoID, Dublin Core, and DCAT with homoiconic containers (databases describing themselves), metamorphic transformations (provable representation changes), and temporal cartography (tracking how maps emerge from journeys of observation). We formalize these concepts using dependent types (Idris2), category theory, and RDF/SPARQL extensions. This position paper articulates the paradigm shift, sketches the architecture, and calls for collaboration in building cartographic infrastructure for the digital age.

== Introduction

=== The Schrödinger Shift

**Old question**: "Is the cat dead or alive?" +
**Focus**: What's inside THIS box?

For decades, quantum mechanics fixated on the measurement problem: one cat, one box, one observation. Applied to data science, this became the black box problem: "What's in this dataset? How does this model work?"

**New question**: "Are there cats beyond?" +
**Focus**: What exists in unexplored reality?

What boxes haven't we built? What creatures aren't cats? What domains lack observation entirely? **What's in the darkness beyond the map's edge?**

Applied to data: "What haven't we measured? What domains are we blind to? Where are the blank spots on our cartography of reality?"

This is not a trivial shift. It inverts the fundamental question of data science.

=== The Vision Blind Spot Analogy

A 2015 Nature paper studied the retinal blind spot—the optic nerve insertion point where photoreceptors are absent <<nature2015>>. This small blind spot (~5° of visual field) has received enormous scientific attention: compensation mechanisms, perceptual filling-in, neural processing.

Yet we ignore the **vast blind spot** behind our eyes: the entire world we cannot see because we face one direction. This 180° blind spot is orders of magnitude larger, yet we treat it as trivial because it's "expected."

**Data science has made the same error.** We obsess over the optic nerve (interpretability of our models) while ignoring the world behind us (unmeasured reality).

=== The Map and the Territory

Alfred Korzybski (1931) established a foundational principle: **"The map is not the territory"** <<korzybski1931>>. Maps are incomplete representations, necessarily omitting details, shaped by the cartographer's perspective and instruments.

**Our databases are maps.** Reality is the territory.

- **D_p (phenomenal databases)**: Our observations, measurements, datasets—the maps we've created
- **D_n (noumenal database)**: Reality itself—the territory we're mapping

The boxes (D_p instances) are **white**—we built them, we understand them. The **darkness** lies in D_n: the vast unmeasured territory beyond our databases.

=== Emerging Maps on Journeys

Traditional cartography assumes maps exist before journeys: "Here's the map. Follow it." But **exploratory cartography inverts this**: journeys create maps.

European exploration (1400s-1900s) provides the model:
- **1400s**: Vast *terra incognita*, "here be dragons"
- **1500s-1800s**: Expeditions progressively map the world
- **Each expedition**: Creates a new map (phenomenal database)
- **Atlases**: Coordinate the emerging maps
- **By 1900s**: World largely mapped, but maps still evolving

**The map emerges from the journey, not before it.**

Data science follows the same pattern:
- **1990s**: Many domains unmeasured/unobserved
- **2000s-2020s**: Sensors, satellites, digital instrumentation create massive observations
- **Each observation**: Phenomenal database (D_p) emerges
- **verisimdb**: Modern atlas coordinating D_p federation
- **2030s+**: Progressively complete cartography of measurable reality

**But we lack the grammatical infrastructure to describe this process formally.**

=== Three Zones of Reality

We partition reality into three zones based on our knowledge:

**Zone 1: White Box (~15% coverage)**
- What we've measured and mapped
- Phenomenal databases (D_p instances) we've created
- Transparent, schema-defined, known provenance
- "Here be data"

**Zone 2: Known Darkness (~25%)**
- Domains we know exist but haven't measured
- Identified blind spots: deep ocean biology, pre-satellite climate data, underrepresented populations
- Known unknowns—specific gaps we can list
- "Here be dragons" (medieval maps marked unconquered territory)

**Zone 3: Unknown Darkness (~60%)**
- Domains we haven't conceived
- Phenomena we lack instruments to detect
- Unknown unknowns—what we don't know we don't know
- "Here be... we don't know what"

**Coverage estimates are uncertain** (we explicitly model low confidence), but the three-zone partition is epistemologically sound. **Acknowledging vast unknown darkness is scientific honesty, not failure.**

=== The Problem with Current Standards

**VoID** (Vocabulary of Interlinked Datasets) <<void2011>>, **Dublin Core** <<dublincore1998>>, and **DCAT** <<dcat2014>> provide vocabularies for describing datasets. They define **terms** (`void:entities`, `dc:creator`, `dcat:Dataset`) but lack:

1. **Compositional grammar**: How to combine metadata elements, validation rules, transformation semantics
2. **Temporal evolution**: How databases evolve as we refine our maps
3. **Cartographic semantics**: Coverage boundaries, blind spots, epistemic humility
4. **Homoiconic containers**: Databases that describe themselves using the same grammar as their contents
5. **Metamorphic transformations**: Provable representation changes (RDF ↔ JSON-LD ↔ Graph ↔ SQL)
6. **Federation coordination**: Atlas-based discovery and gap identification

**We need a grammar, not just a vocabulary.**

=== Contribution

This paper proposes **Journey Grammar for Databases (JGD)**, a formal framework for exploratory data cartography:

1. **Paradigm shift**: From black box obsession to white box in darkness
2. **Formal grammar**: Syntax (EBNF), semantics (Idris2 dependent types), transformations (category theory)
3. **Cartographic primitives**: D_p/D_n classification, spatiotemporal coverage, blind spot tracking
4. **Temporal cartography**: Maps emerge from journeys, tracked via verisimdb
5. **Epistemic humility**: Machine-readable three-zone model, explicit unknown unknowns
6. **Atlas-based federation**: Coordinated exploration, gap identification, discovery

**We stand on giants' shoulders** (Korzybski's cartography, Kant's epistemology, relational algebra) **to build new infrastructure**: systematic application of cartographic principles to database metadata.

**This is a position paper.** We articulate the paradigm shift, sketch the architecture, and call for collaboration. Implementation follows (roadmap provided).

== The Paradigm Shift: White Box in Darkness

=== Traditional View: Black Box Problem

**Obsession**: Explain the model (open the black box)

**Typical concerns**:
- "Why did the neural network make this prediction?"
- "How does this recommendation system work?"
- "Can we interpret this classifier's decision?"

**Solutions proposed**:
- LIME, SHAP (local interpretability) <<ribeiro2016>>
- Attention visualization
- Gradient inspection
- Simpler models for interpretability

**Focus**: Understanding the TOOL (the box we built)

=== Inverted View: White Box in Darkness

**Perspective**: The model is transparent. The territory is dark.

**Different questions**:
- "What reality is this model helping us discover?"
- "What domains aren't in our training data?"
- "What populations haven't we measured?"
- "What patterns exist beyond our dataset's edge?"
- "Where are the blind spots?"

**Approach**:
- Map coverage gaps in training data
- Identify underrepresented populations (Zone 2)
- Guide data collection for blind spots
- Explore unknown risk factors (Zone 3)

**Focus**: Exploring REALITY (beyond the box)

=== Concrete Example: Cancer Prediction Model

**Black box framing**:

> "This neural network predicts cancer risk, but we don't understand it!"
>
> → Apply LIME/SHAP for interpretability +
> → Visualize attention weights +
> → Use simpler linear models

**White box in darkness framing**:

> "This neural network predicts cancer risk. We understand its mechanism:
>
> - Convolutional layers extract image features
> - Dense layers classify patterns
> - Softmax outputs probabilities
>
> We know HOW it works. **What's in the DARKNESS?**
>
> - What cancers aren't in our training data? (Zone 2)
> - What populations haven't we measured? (Zone 2)
> - What risk factors haven't we discovered? (Zone 3)
> - What patterns exist beyond our dataset's edge? (Zone 3)"
>
> → Map coverage gaps in training data +
> → Identify underrepresented populations +
> → Guide data collection for blind spots +
> → Explore unknown risk factors

**The model is the white box. The disease landscape is the dark territory.**

=== Why This Matters for AI Ethics

**Current AI ethics** focuses on:
- Algorithmic fairness (bias in models)
- Transparency (explainability)
- Accountability (who's responsible)

**These are important but insufficient.** They assume the model/dataset is the problem.

**Cartographic AI ethics** asks:
- What populations are MISSING from datasets? (coverage gaps)
- What harms might exist that we HAVEN'T MEASURED? (Zone 3)
- Where should we DEPLOY models? (only within white box coverage)
- Where should we NOT DEPLOY? (in darkness—unknown risks)

**Datasheets for Datasets** <<gebru2018>> and **Model Cards** <<mitchell2019>> document limitations but lack **cartographic infrastructure** for:
- Federating knowledge of gaps across datasets
- Guiding exploration to fill blind spots
- Querying temporal evolution ("what coverage existed in 2020?")

**JGD provides this infrastructure.**

=== Implication: Data Science as Exploration

**Traditional data engineering**:
- Build databases
- Optimize queries
- Ensure reliability
- **Focus**: The infrastructure

**Exploratory data cartography**:
- Discover domains
- Fill coverage gaps
- Resolve contradictions
- **Focus**: The territory

**We are explorers stepping into darkness**, progressively expanding the white box as we map the unknown.

== Journey Grammar for Databases

=== Core Concepts

==== D_p: Phenomenal Databases (The Maps)

A **phenomenal database** is an observational artifact: measurements, sensor data, survey responses, transaction logs—any structured collection of observations about reality.

**Key properties**:
- **Constructed**: Humans/instruments created it
- **Partial**: Incomplete coverage of D_n
- **Perspectival**: Reflects observer's instruments, biases, limitations
- **Temporal**: Snapshot of knowledge at time T
- **Transparent**: We can inspect contents, understand schema

**Examples**: Climate sensor network data, genomic sequences, economic indicators, social media logs, medical imaging datasets.

**Notation**: D_p instances (e.g., `ClimateDB`, `GenomeDB`, `EconDB`)

==== D_n: Noumenal Database (The Territory)

The **noumenal database** is reality itself: the complete state of the world, independent of our observations.

**Key properties**:
- **Independent**: Exists whether we observe it or not
- **Unknowable in totality**: We can only approximate via D_p instances
- **The limit**: What all D_p instances collectively approach (but never reach)
- **Opaque**: We cannot directly inspect D_n, only observe it through D_p

**D_n is NOT a database we can query.** It's a **conceptual reference point**: the territory our maps approximate.

**Notation**: D_n (singular, the noumenal reality)

==== Coverage: Spatiotemporal Extent

Every D_p instance has **coverage**: the region of D_n it observes.

**Spatial coverage**: Geographic region, population subset, domain scope

```turtle
:ClimateDB a jgd:D_p ;
    jgd:spatialCoverage :NorthernHemisphere ;
    jgd:resolution "1km grid" .
```

**Temporal coverage**: Time range of observations

```turtle
:ClimateDB jgd:temporalCoverage [
    jgd:start "1980-01-01"^^xsd:date ;
    jgd:end "2025-01-31"^^xsd:date
] .
```

**Coverage defines the white box boundary** for this D_p instance.

==== Blind Spots: Known Gaps (Zone 2)

**Blind spots** are identified coverage gaps: regions of D_n we know we're missing.

```turtle
:ClimateDB jgd:knownBlindSpots [
    jgd:spatial :SouthernOceans ;
    jgd:temporal "pre-1950" ;
    jgd:reason "Limited sensor deployment before satellite era"
] .
```

**Blind spots are cartographic honesty**: explicitly marking "here be dragons."

**Importance**: Guides exploration priorities (fill blind spots first).

==== Epistemic Humility: Unknown Unknowns (Zone 3)

Beyond blind spots lie **unknown unknowns**: domains we haven't conceived.

```turtle
:GlobalAtlas jgd:epistemicHumility [
    rdfs:comment "We estimate ~15% white box, ~25% known darkness, ~60% unknown darkness" ;
    jgd:confidenceInEstimate jgd:VeryLow ;
    jgd:acknowledgment "These percentages are uncertain. The point is vast darkness exists."
] .
```

**This is machine-readable humility**: admitting ignorance in queryable RDF.

=== Homoiconic Containers

**Homoiconicity** (from Lisp): Code is data, data is code. Same representation for both.

**Applied to databases**: Container metadata uses the same grammar as data contents.

**Example**:

```turtle
# verisimdb is both a storage container AND a D_p instance
:VerisimDB a jgd:StorageContainer, jgd:D_p ;
    # As container: stores other D_p instances
    jgd:stores :ClimateDB, :EconomicDB, :GenomicDB ;

    # As D_p: observes database evolution domain
    jgd:observes jgd-domain:DatabaseEvolution ;
    jgd:temporalCoverage "2020-2026" ;

    # Homoiconic: describes itself using JGD
    jgd:describedBy jgd:JourneyGrammar .
```

**verisimdb is a map that maps other maps.** It describes its own structure using the grammar it enforces for contents.

**Benefits**:
- Unified formalism for container and contents
- Enables reflection (containers examine themselves)
- Simplifies tooling (one grammar for everything)

=== Metamorphic Transformations

**Phenomenal databases change representations** without changing semantics: RDF ↔ JSON-LD ↔ Property Graph ↔ SQL.

**Metamorphic transformation**: Representation change preserving invariants (coverage, provenance, semantics).

**Formalization**: Category theory

- **Categories**: Each storage model (RDF, Graph, SQL) is a category
- **Functors**: Transformations between categories
- **Natural transformations**: Prove equivalence

**Idris2 types prove correctness**:

```idris
-- Transformation preserves coverage
transformPreservesCoverage :
  (t : Transform D_p_RDF D_p_Graph) ->
  coverage (transform t db) = coverage db
```

**Example**:

```
ClimateDB (RDF/Turtle)
    ↓ [metamorphic transform]
ClimateDB (JSON-LD)
    ↓ [metamorphic transform]
ClimateDB (Neo4j Property Graph)
    ↓ [metamorphic transform]
ClimateDB (PostgreSQL + PostGIS)
```

**All representations preserve**:
- Spatiotemporal coverage
- Provenance
- Blind spot identification
- Uncertainty metrics

**Storage-model independence** without semantic loss.

=== Temporal Cartography: Maps Emerge from Journeys

**Traditional metadata**: Static snapshot ("this database covers 2010-2020")

**Cartographic metadata**: Temporal evolution tracking

**Example**:

```
Time T₀ (1950): No global climate database exists → Darkness
    ↓ [Thermometer network deployed]
Time T₁ (1970): Sparse surface temperature records → ClimateDB_v1 emerges
    ↓ [Satellite launches]
Time T₂ (1990): Satellite data added → ClimateDB_v2 (expanded coverage)
    ↓ [High-resolution sensors]
Time T₃ (2010): 1km resolution grid → ClimateDB_v3 (improved resolution)
    ↓ [Real-time streaming]
Time T₄ (2025): Real-time global coverage → ClimateDB_v4 (current state)
```

**verisimdb tracks this evolution**:

```turtle
:ClimateDB jgd:versionHistory :ClimateDB-History .

:ClimateDB-History vsim:snapshots (
    :ClimateDB_v1970  # Sparse thermometers
    :ClimateDB_v1990  # Added satellites
    :ClimateDB_v2010  # High resolution
    :ClimateDB_v2025  # Real-time
) .

# Cartographic delta: what improved?
:ClimateDB vsim:cartographicDelta [
    vsim:from :ClimateDB_v2010 ;
    vsim:to :ClimateDB_v2025 ;
    vsim:blindSpotFilled :ArcticRegion ;
    vsim:uncertaintyReduced 0.15 ;
    vsim:resolutionImproved "1km → 500m"
] .
```

**Temporal queries** (VQL extension):

```sparql
# What coverage did we have in 2000?
SELECT ?db ?coverage
AT TIME "2000-01-01T00:00:00Z"
WHERE {
    ?db a jgd:D_p ;
        jgd:spatialCoverage ?coverage .
}

# How did blind spots evolve?
SELECT ?db ?blindspot ?when_filled WHERE {
    ?db vsim:cartographicDelta ?delta .
    ?delta vsim:blindSpotFilled ?blindspot ;
           vsim:filledAt ?when_filled .
}
```

**The map is the trace of the journey.**

=== Federation: Atlas-Based Coordination

**Problem**: Scattered D_p instances, uncoordinated collection, duplicated efforts, unknown gaps.

**Solution**: **verisimdb as cartographic atlas**

**Atlas functions**:
1. **Index D_p instances**: Catalog what maps exist
2. **Track coverage**: Spatial/temporal extent of each D_p
3. **Identify gaps**: Where are blind spots across federation?
4. **Coordinate exploration**: Prioritize which darkness to explore next
5. **Enable discovery**: Query for D_p covering region/time

**Architecture**:

```
┌─────────────────────────────────────────┐
│ verisimdb (Cartographic Atlas)          │
│ - Indexes all D_p instances             │
│ - Temporal queries, cartographic deltas │
│ - Gap identification, exploration guide │
└──────────────┬──────────────────────────┘
               │ (federation)
     ┌─────────┴─────────┬────────────┐
     ▼                   ▼            ▼
┌──────────┐      ┌──────────┐  ┌──────────┐
│PostgreSQL│      │  Neo4j   │  │ MongoDB  │
│Climate   │      │ Economic │  │ Genomic  │
│D_p       │      │ D_p      │  │ D_p      │
└──────────┘      └──────────┘  └──────────┘
```

**Discovery query**:

```sparql
# Find D_p instances covering Europe in 2020-2025
SELECT ?db ?coverage WHERE {
    ?db a jgd:D_p ;
        jgd:spatialCoverage ?spatial ;
        jgd:temporalCoverage ?temporal .
    ?spatial geo:sfIntersects :Europe .
    ?temporal jgd:overlaps "2020/2025" .
}
```

**Gap analysis**:

```sparql
# Where are blind spots concentrated?
SELECT ?region (COUNT(?blindspot) AS ?gap_count) WHERE {
    ?db a jgd:D_p ;
        jgd:knownBlindSpots ?blindspot .
    ?blindspot jgd:spatial ?region .
}
GROUP BY ?region
ORDER BY DESC(?gap_count)
```

**Atlas guides exploration**: "Most blind spots in Southern Oceans → prioritize deployment there."

== Architecture Sketch

We sketch JGD's four-layer architecture. Full implementation is future work (see Roadmap).

=== Layer 1: Formal Specification (Idris2)

**Dependent types** prove correctness properties at compile-time.

**Example**:

```idris
-- D_p with non-empty name (proven)
record D_p where
  constructor MkD_p
  name : String
  {auto 0 nameNonEmpty : So (length name > 0)}
  observes : Domain
  spatialCoverage : SpatialCoverage
  temporalCoverage : TemporalCoverage
  knownBlindSpots : List BlindSpot

-- Coverage is non-null
data SpatialCoverage : Type where
  MkSpatialCoverage :
    (geom : Geometry) ->
    {auto 0 nonNull : So (notNull geom)} ->
    SpatialCoverage

-- Metamorphic transform preserves coverage
transformPreservesCoverage :
  (t : Transform D_p_A D_p_B) ->
  coverage (transform t db) = coverage db
```

**Benefits**:
- Compile-time proofs of metadata correctness
- Impossible to create invalid D_p (name can't be empty)
- Transformations provably preserve invariants

**Generates C ABI headers** for FFI layer.

=== Layer 2: C ABI Implementation (Zig)

**Zig** provides memory-safe C ABI implementation.

```zig
// Opaque handle (non-null guaranteed by Idris2 types)
pub const D_p_Handle = opaque {};

// Create D_p instance
export fn jgd_create_d_p(
    name: [*:0]const u8,
    observes: [*:0]const u8,
) ?*D_p_Handle {
    // Allocate, validate, return handle
    // Returns null only if allocation fails
}

// Query coverage
export fn jgd_get_spatial_coverage(
    handle: *D_p_Handle,
    out_wkt: [*]u8,
    out_len: *usize,
) bool {
    // Get spatial coverage as WKT (Well-Known Text)
}
```

**Benefits**:
- Cross-platform C ABI (works everywhere)
- Memory-safe (Zig's safety guarantees)
- Zero runtime dependencies

=== Layer 3: Language Bindings

**Rust**, **Julia**, **ReScript**, **Python** bindings wrap the C FFI.

**Example (Rust)**:

```rust
use jgd_sys::*;

pub struct D_p {
    handle: *mut D_p_Handle,
}

impl D_p {
    pub fn new(name: &str, observes: &str) -> Result<Self> {
        let handle = unsafe {
            jgd_create_d_p(
                name.as_ptr() as *const i8,
                observes.as_ptr() as *const i8,
            )
        };
        // ... null check, wrap in Result
    }

    pub fn spatial_coverage(&self) -> Result<String> {
        // ... call jgd_get_spatial_coverage
    }
}
```

**Brings JGD to ecosystems**: Rust for systems, Julia for data science, ReScript for web, Python for ML.

=== Layer 4: Applications & Tooling

**CLI tools**:
- `jgd create` - Create new D_p metadata
- `jgd validate` - Validate against SHACL shapes
- `jgd transform` - Metamorphic transformations
- `jgd query` - Query verisimdb atlas

**Web UI** (ReScript):
- Visual metadata creation
- Interactive coverage maps
- Blind spot visualization
- Temporal evolution charts

**Batch scripts** (Julia):
- Convert VoID/DCAT to JGD at scale
- Analyze coverage gaps across federation
- Generate exploration priorities

=== Storage Independence

**JGD core** is storage-agnostic. Works on:
- RDF triplestores (Jena, Virtuoso, Blazegraph)
- Property graphs (Neo4j, ArangoDB)
- SQL databases (PostgreSQL, MySQL)
- Document stores (MongoDB, CouchDB)
- **verisimdb** (canonical implementation with full temporal features)

**Minimal backend requirements**:
1. Structured storage for D_p metadata
2. Query interface (SPARQL, SQL, or equivalent)
3. Federation support (can reference other D_p instances)
4. Homoiconic capability (container can describe itself)

**verisimdb adds**:
- Temporal versioning (Git-like semantics)
- Time-travel queries ("what coverage existed on date X?")
- Cartographic deltas (track blind spot filling over time)
- VQL extensions (SPARQL + temporal operators)

== Implications & Future Work

=== Reframing AI Ethics

**From**: "Explain the algorithm" (interpretability)

**To**: "Map the coverage gaps" (cartography)

**Concrete impact**:
- **Bias audits** become **coverage audits**: Which populations are in Zone 2 (missing)?
- **Model cards** become **cartographic metadata**: Spatiotemporal coverage, known blind spots
- **Deployment decisions**: Only deploy within white box coverage, not in darkness

**Example**: Medical AI trained on US hospital data

- **Old question**: "Can we explain why the model diagnosed this patient?"
- **New question**: "What populations are MISSING from the training data? Where should we NOT deploy?"

**JGD answer**:

```turtle
:MedicalAI_TrainingData a jgd:D_p ;
    jgd:spatialCoverage :USA_Hospitals ;
    jgd:temporalCoverage "2010-2020" ;
    jgd:knownBlindSpots [
        jgd:population "Sub-Saharan Africa" ;
        jgd:population "Rural Southeast Asia" ;
        jgd:reason "No data sources"
    ] .
```

**Do NOT deploy in blind spot regions.** Collect data first, then deploy.

=== Guiding Scientific Exploration

**Research funding** currently allocated by:
- Investigator reputation
- Institutional prestige
- Political priorities
- Disciplinary silos

**Cartographic funding** would prioritize:
- **Blind spot coverage**: Fill Zone 2 gaps first
- **Interdisciplinary gaps**: Domains at boundaries of fields
- **Temporal completeness**: Extend coverage backward/forward
- **Unknown unknown exploration**: Speculative instruments for Zone 3

**JGD enables**:

```sparql
# Which scientific domains have the most blind spots?
SELECT ?domain (COUNT(?blindspot) AS ?gap_count) WHERE {
    ?db a jgd:D_p ;
        jgd:observes ?domain ;
        jgd:knownBlindSpots ?blindspot .
}
GROUP BY ?domain
ORDER BY DESC(?gap_count)
LIMIT 10
```

**Answer guides where to direct resources.**

=== Knowledge Management: Exploration Guidance

**Traditional knowledge management**: Organize what we know

**Cartographic knowledge management**: Guide exploration of what we don't

**Questions JGD enables**:
- What knowledge gaps block critical projects?
- Which blind spots are highest priority?
- Where should research funding go?
- How do we measure exploration progress?

**Metric**: **White box expansion rate**

```
2020: 14.2% coverage
2025: 15.1% coverage
Growth: +0.9% over 5 years

Target 2030: 17% coverage
Required: ~0.4% annual growth
```

**If white box grows from 15% → 25% by 2050, that's transformative.**

=== Future Work: Roadmap

**Phase 1: Formal Specification (Q1 2026)** ✓ In Progress
- EBNF grammar for JGD syntax
- Idris2 type system for D_p/D_n
- SHACL shapes for runtime validation
- JSON-LD context, OWL ontology
- Category theory for metamorphic transforms

**Phase 2: Homoiconic Container Model (Q2 2026)**
- `jgd:StorageContainer` abstract type
- Self-description and reflection APIs
- verisimdb as reference implementation

**Phase 3: Metamorphic Library (Q3 2026)**
- Transformation catalog (RDF ↔ JSON-LD ↔ Graph ↔ SQL)
- Idris2 proofs of invariant preservation
- Round-trip validation tests

**Phase 4: Integration Ecosystem (Q4 2026)**
- verisimdb atlas deployment
- SPARQL/VQL endpoint with temporal queries
- D_p discovery and gap analysis tools

**Phase 5: Tooling & Libraries (Q1 2027)**
- Zig FFI library
- Rust CLI, ReScript web UI
- Julia batch scripts
- Python/JavaScript bindings

**Phase 6: Documentation & Community (Q2 2027)**
- Specification website
- Tutorial series, example datasets
- Academic publication (full technical paper)
- Community forum

**Success metrics by 2027**:
- >1000 D_p instances created
- >100,000 databases indexed in verisimdb atlas
- White box grows 15% → 17% (measurable expansion)
- >10,000 Zone 2 blind spots cataloged
- >10 institutions using JGD

=== Call for Collaboration

**We seek collaborators with expertise in**:

- **Category theory**: Formalizing metamorphic transformations
- **Dependent types**: Idris2 implementation of D_p/D_n types
- **Semantic web**: RDF, SPARQL, OWL ontologies
- **Data science**: Blind spot identification, coverage metrics
- **verisimdb**: Temporal database integration
- **Technical writing**: Documentation, tutorials, examples

**Contact**: jonathan.jewell@open.ac.uk

**Repository**: https://github.com/hyperpolymath/metadata-grammar

== Related Work

_[See ARXIV-RELATED-WORK.adoc for full section—abbreviated here for space]_

**Cartography & Geography**: We build on Korzybski (1931) map/territory distinction <<korzybski1931>>, critical cartography (Harley, 1989 <<harley1989>>), and GIS spatial data quality research <<goodchild2009>>.

**Philosophy**: We adapt Kant's (1781) phenomenal/noumenal distinction <<kant1781>>, epistemology of known/unknown unknowns <<rescher2009>>, and epistemic humility in science.

**Database Metadata**: We extend VoID <<void2011>>, Dublin Core <<dublincore1998>>, and DCAT <<dcat2014>> with compositional grammar, temporal cartography, and homoiconic containers.

**Temporal Databases**: We build on temporal versioning (Snodgrass, 1999 <<snodgrass1999>>) and Git-like semantics, applying them to metadata evolution.

**AI Ethics**: We reframe XAI interpretability research <<ribeiro2016>> <<doshivelez2017>> and fairness work <<barocas2016>> <<gebru2018>> from "explain the model" to "map the coverage gaps."

**Our contribution**: Systematic application of cartographic principles to database metadata, formalized as grammar with dependent types, enabling temporal queries and federation coordination.

== Conclusion

**For two decades, we obsessed over black boxes.** We built interpretability tools, simplified models, visualized attention weights—all focused on understanding our artifacts.

**We were looking in the wrong direction.**

**Our boxes are white.** We built them. We know their schemas. We can inspect their contents. Phenomenal databases (D_p instances) are transparent.

**The darkness lies beyond**: the vast unmeasured territory of noumenal reality (D_n) that our databases only partially map.

**Journey Grammar for Databases** inverts the paradigm:

- **From**: Interpretability (opening black boxes)
- **To**: Cartography (mapping dark territory)

- **From**: Understanding our tools
- **To**: Exploring the unknown

- **From**: Pretending we know everything
- **To**: Epistemic humility about vast darkness

**We are cartographers of the digital age.** Our databases are maps. Reality is the territory. The maps emerge from journeys of observation, progressively refining but never complete.

**JGD provides the grammatical infrastructure**:
- Formal classification (D_p phenomenal databases, D_n noumenal reality)
- Spatiotemporal coverage tracking
- Blind spot identification (Zone 2: known darkness)
- Epistemic humility (Zone 3: unknown unknowns ~60%)
- Homoiconic containers (databases describing themselves)
- Metamorphic transformations (provable representation changes)
- Temporal cartography (maps emerging from journeys)
- Atlas-based federation (coordinated exploration)

**This position paper stakes the paradigm shift.** Implementation follows (roadmap provided). We invite collaboration in building cartographic infrastructure for mapping measurable reality.

**The boxes are white. The territory is dark. Let's explore.**

== Acknowledgments

This work builds on foundational insights from Alfred Korzybski (map/territory), Immanuel Kant (phenomenal/noumenal), and the rich traditions of critical cartography, epistemology, and semantic web research. We thank the verisimdb project for inspiring the temporal cartography vision.

== References

[bibliography]
- [[[korzybski1931]]] Korzybski, A. (1931). *Science and Sanity: An Introduction to Non-Aristotelian Systems and General Semantics*. Institute of General Semantics.

- [[[kant1781]]] Kant, I. (1781/1998). *Critique of Pure Reason*. Cambridge University Press.

- [[[harley1989]]] Harley, J. B. (1989). Deconstructing the map. *Cartographica*, 26(2), 1-20.

- [[[goodchild2009]]] Goodchild, M. F. (2009). Geographic information systems and science: today and tomorrow. *Annals of GIS*, 15(1), 3-9.

- [[[void2011]]] Alexander, K., Cyganiak, R., Hausenblas, M., & Zhao, J. (2011). Describing Linked Datasets with the VoID Vocabulary. W3C Interest Group Note.

- [[[dublincore1998]]] Weibel, S., Kunze, J., Lagoze, C., & Wolf, M. (1998). Dublin Core Metadata for Resource Discovery. RFC 2413.

- [[[dcat2014]]] Maali, F., & Erickson, J. (2014). Data Catalog Vocabulary (DCAT). W3C Recommendation.

- [[[snodgrass1999]]] Snodgrass, R. T. (1999). *Developing Time-Oriented Database Applications in SQL*. Morgan Kaufmann.

- [[[rescher2009]]] Rescher, N. (2009). *Ignorance: On the Wider Implications of Deficient Knowledge*. University of Pittsburgh Press.

- [[[ribeiro2016]]] Ribeiro, M. T., Singh, S., & Guestrin, C. (2016). "Why should I trust you?" Explaining the predictions of any classifier. *KDD 2016*, 1135-1144.

- [[[doshivelez2017]]] Doshi-Velez, F., & Kim, B. (2017). Towards a rigorous science of interpretable machine learning. *arXiv preprint arXiv:1702.08608*.

- [[[barocas2016]]] Barocas, S., & Selbst, A. D. (2016). Big data's disparate impact. *California Law Review*, 104, 671.

- [[[gebru2018]]] Gebru, T., Morgenstern, J., Vecchione, B., Vaughan, J. W., Wallach, H., Daumé III, H., & Crawford, K. (2018). Datasheets for datasets. *arXiv preprint arXiv:1803.09010*.

- [[[mitchell2019]]] Mitchell, M., Wu, S., Zaldivar, A., Barnes, P., Vasserman, L., Hutchinson, B., ... & Gebru, T. (2019). Model cards for model reporting. *FAT* 2019*, 220-229.

- [[[nature2015]]] Simulated reference for vision blind spot analogy (actual citation TBD).

== License

This document is licensed under the Palimpsest Meta-Philosophical License (PMPL-1.0-or-later).

SPDX-License-Identifier: PMPL-1.0-or-later
